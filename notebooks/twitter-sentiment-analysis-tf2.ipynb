{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "92b885dd147dac19bd0a33db3cd0da100bd5bc23"
   },
   "source": [
    "# Twitter Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original notebook was based on TF1. This notebook modifies the dependencies to TF2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data\n",
    "!bash ../src/data/download_dataset.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(tf.test.is_built_with_cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "70282bce8b42a51e4d44f2c7d85c4ca9567b0fd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (20.0.2)\n",
      "Collecting gensim\n",
      "  Downloading gensim-3.8.1-cp36-cp36m-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 24.2 MB 13.3 MB/s eta 0:00:01   |██████                          | 4.6 MB 2.8 MB/s eta 0:00:07\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-1.9.0.tar.gz (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 7.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.0)\n",
      "Collecting boto>=2.32\n",
      "  Downloading boto-2.49.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 8.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.8.1->gensim) (2.23.0)\n",
      "Collecting boto3\n",
      "  Downloading boto3-1.12.7-py2.py3-none-any.whl (128 kB)\n",
      "\u001b[K     |████████████████████████████████| 128 kB 14.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->smart-open>=1.8.1->gensim) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)\n",
      "Collecting s3transfer<0.4.0,>=0.3.0\n",
      "  Downloading s3transfer-0.3.3-py2.py3-none-any.whl (69 kB)\n",
      "\u001b[K     |████████████████████████████████| 69 kB 7.7 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
      "  Downloading jmespath-0.9.5-py2.py3-none-any.whl (24 kB)\n",
      "Collecting botocore<1.16.0,>=1.15.7\n",
      "  Downloading botocore-1.15.7-py2.py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 8.5 MB/s eta 0:00:01     |██████████████████████████▌     | 4.9 MB 8.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting docutils<0.16,>=0.10\n",
      "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
      "\u001b[K     |████████████████████████████████| 547 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.7->boto3->smart-open>=1.8.1->gensim) (2.8.1)\n",
      "Building wheels for collected packages: smart-open\n",
      "  Building wheel for smart-open (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for smart-open: filename=smart_open-1.9.0-py3-none-any.whl size=79331 sha256=345f6359e022fb9fc138fa3792f39a316cd7fa6c2a09ef58f5074636b6d7faf6\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/9f/cd/dbf5c1362c59abb699a218c1151679033b8ccb5b6db559d512\n",
      "Successfully built smart-open\n",
      "Installing collected packages: boto, docutils, jmespath, botocore, s3transfer, boto3, smart-open, gensim\n",
      "Successfully installed boto-2.49.0 boto3-1.12.7 botocore-1.15.7 docutils-0.15.2 gensim-3.8.1 jmespath-0.9.5 s3transfer-0.3.3 smart-open-1.9.0\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.0.1-cp36-cp36m-manylinux1_x86_64.whl (10.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.1 MB 2.9 MB/s eta 0:00:01    |██████████████████████████      | 8.2 MB 2.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2019.3-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[K     |████████████████████████████████| 509 kB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.0.1 pytz-2019.3\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 3.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.14.0)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1450718 sha256=d564a9012568487931b18b7243400661632c42d72ea6072618aadcb46ff7cd5a\n",
      "  Stored in directory: /root/.cache/pip/wheels/e3/c9/b0/ed26a73ef75a53145820825afa8e2d2c9b30fe9f6c10cd3202\n",
      "Successfully built nltk\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.4.5\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.22.1-cp36-cp36m-manylinux1_x86_64.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting joblib>=0.11\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 12.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Building wheels for collected packages: sklearn\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=2397 sha256=f66fea84fb7de74a53f6ea78ac78d320f083e88f4e355d59f2f7a7b8a1fe80f8\n",
      "  Stored in directory: /root/.cache/pip/wheels/23/9d/42/5ec745cbbb17517000a53cecc49d6a865450d1f5cb16dc8a9c\n",
      "Successfully built sklearn\n",
      "Installing collected packages: joblib, scikit-learn, sklearn\n",
      "Successfully installed joblib-0.14.1 scikit-learn-0.22.1 sklearn-0.0\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.8.28-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-ml-py3>=7.352.0\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.14.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.23.0)\n",
      "Collecting PyYAML>=3.10\n",
      "  Downloading PyYAML-5.3.tar.gz (268 kB)\n",
      "\u001b[K     |████████████████████████████████| 268 kB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 3.4 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting configparser>=3.8.1\n",
      "  Downloading configparser-4.0.2-py2.py3-none-any.whl (22 kB)\n",
      "Collecting gql==0.2.0\n",
      "  Downloading gql-0.2.0.tar.gz (18 kB)\n",
      "Collecting watchdog>=0.8.3\n",
      "  Downloading watchdog-0.10.2.tar.gz (95 kB)\n",
      "\u001b[K     |████████████████████████████████| 95 kB 3.3 MB/s eta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.8.1)\n",
      "Collecting psutil>=5.0.0\n",
      "  Downloading psutil-5.7.0.tar.gz (449 kB)\n",
      "\u001b[K     |████████████████████████████████| 449 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting Click>=7.0\n",
      "  Downloading Click-7.0-py2.py3-none-any.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 8.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.0-py3-none-any.whl (450 kB)\n",
      "\u001b[K     |████████████████████████████████| 450 kB 7.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-0.5.0.tar.gz (6.1 kB)\n",
      "Collecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Collecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-0.14.2-py2.py3-none-any.whl (96 kB)\n",
      "\u001b[K     |████████████████████████████████| 96 kB 5.7 MB/s  eta 0:00:01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.11.28)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.0.0->wandb) (2.6)\n",
      "Collecting graphql-core<2,>=0.5.0\n",
      "  Downloading graphql-core-1.1.tar.gz (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 9.5 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\n",
      "Collecting pathtools>=0.1.1\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "Collecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.2-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 2.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting smmap<4,>=3.0.1\n",
      "  Downloading smmap-3.0.1-py2.py3-none-any.whl (25 kB)\n",
      "Building wheels for collected packages: nvidia-ml-py3, PyYAML, subprocess32, gql, watchdog, psutil, shortuuid, graphql-core, promise, pathtools\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=20119 sha256=111b1c076b364dd240a399cac3071450855cef254143422d3e9a9da89224a42a\n",
      "  Stored in directory: /root/.cache/pip/wheels/7f/26/a3/33f2079871e2bebb3f53a2b21c3ec64129b8efdd18a6263a52\n",
      "  Building wheel for PyYAML (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for PyYAML: filename=PyYAML-5.3-cp36-cp36m-linux_x86_64.whl size=45519 sha256=408d84c200d815053e418fd79318b3cb01bae598a030a7cea0653e6fd256d0c5\n",
      "  Stored in directory: /root/.cache/pip/wheels/b1/86/0d/10e6c39d3a2b85ba807d7657ee80f08cc16c03f2aa2adf8e46\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=3299 sha256=4fd1f3e1c9cc5451f8e356a46aced716c65c0cb599cbdccb29f4c4e95f65b08b\n",
      "  Stored in directory: /root/.cache/pip/wheels/44/3a/ab/102386d84fe551b6cedb628ed1e74c5f5be76af8b909aeda09\n",
      "  Building wheel for gql (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gql: filename=gql-0.2.0-py3-none-any.whl size=8312 sha256=0a52ec0071979ffb3e08adce3c1a8689b8c12ef982f50af6878b5d95cfcbab90\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/ef/a7/f614a774441771008595df4a0ac8cdf866194d24a0e431c04b\n",
      "  Building wheel for watchdog (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for watchdog: filename=watchdog-0.10.2-py3-none-any.whl size=74801 sha256=adb6b8e72176b775f990dd950b7843cc5a1e7f6962957b8924b6013a8e56ca2f\n",
      "  Stored in directory: /root/.cache/pip/wheels/25/94/87/c9e81967b98f25a0c0064f42ce71d494c9df4164f613ccee92\n",
      "  Building wheel for psutil (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for psutil: filename=psutil-5.7.0-cp36-cp36m-linux_x86_64.whl size=279873 sha256=46fea713dc20c20758981434ea9ada04ec094f226b50db1e93c62a60dd84133d\n",
      "  Stored in directory: /root/.cache/pip/wheels/a1/d9/f2/b5620c01e9b3e858c6877b1045fda5b115cf7df6490f883382\n",
      "  Building wheel for shortuuid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for shortuuid: filename=shortuuid-0.5.0-py3-none-any.whl size=5512 sha256=44c094dc797e86615f37accf828664f73051153d3de2e2aa64ea0715535f30e9\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/4c/6e/7a00356c3a284443d0e3bfa8710310e8bc6ef5d6144e011bc8\n",
      "  Building wheel for graphql-core (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for graphql-core: filename=graphql_core-1.1-py3-none-any.whl size=105789 sha256=2244a2784fd627e9421b4c3d781b66e8852ff9ddcc4e3c4da53192c486f05bc9\n",
      "  Stored in directory: /root/.cache/pip/wheels/ef/ae/d6/1dfc3868f8c53b7961af004b85c1c48c07a7d639e06c3a5b08\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=23950 sha256=73487bc15573a08c8f417a04815510beb2291a9d1662e3876ebb09f73d20a5a2\n",
      "  Stored in directory: /root/.cache/pip/wheels/59/9a/1d/3f1afbbb5122d0410547bf9eb50955f4a7a98e53a6d8b99bd1\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8604 sha256=c4be09cc409be683e0382a856feb76d2a874c05a20866fe37d264bd68a131988\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/ea/90/e37d463fb3b03848bf715080595de62545266f53dd546b2497\n",
      "Successfully built nvidia-ml-py3 PyYAML subprocess32 gql watchdog psutil shortuuid graphql-core promise pathtools\n",
      "Installing collected packages: nvidia-ml-py3, PyYAML, subprocess32, configparser, promise, graphql-core, gql, pathtools, watchdog, psutil, Click, smmap, gitdb, GitPython, shortuuid, docker-pycreds, sentry-sdk, wandb\n",
      "Successfully installed Click-7.0 GitPython-3.1.0 PyYAML-5.3 configparser-4.0.2 docker-pycreds-0.4.0 gitdb-4.0.2 gql-0.2.0 graphql-core-1.1 nvidia-ml-py3-7.352.0 pathtools-0.1.2 promise-2.3 psutil-5.7.0 sentry-sdk-0.14.2 shortuuid-0.5.0 smmap-3.0.1 subprocess32-3.5.4 wandb-0.8.28 watchdog-0.10.2\n"
     ]
    }
   ],
   "source": [
    "# install lab dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install gensim --upgrade\n",
    "!pip install pandas --upgrade\n",
    "!pip install nltk --upgrade\n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "303e72966af732ddef0bd8108a321095314e44af"
   },
   "outputs": [],
   "source": [
    "# DataFrame\n",
    "import pandas as pd\n",
    "\n",
    "# Matplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TensorFLow\n",
    "# import tensorflow as tf is not working\n",
    "import tensorflow \n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout, Embedding, Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from  nltk.stem import SnowballStemmer\n",
    "\n",
    "# Word2vec\n",
    "import gensim\n",
    "\n",
    "# Utility\n",
    "import re\n",
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import logging\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "\n",
    "# Set log\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "35e1a89dead5fd160e4c9a024a21d2e569fc89ff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8b01a07df001e4abcc745900336c4db06e455f3"
   },
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "180f0dd2a95419e4602b5c0229822b0111c826f6"
   },
   "outputs": [],
   "source": [
    "# DATASET\n",
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "TRAIN_SIZE = 0.8\n",
    "\n",
    "# TEXT CLENAING\n",
    "TEXT_CLEANING_RE = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\"\n",
    "\n",
    "# WORD2VEC \n",
    "W2V_SIZE = 300\n",
    "W2V_WINDOW = 7\n",
    "W2V_EPOCH = 32\n",
    "W2V_MIN_COUNT = 10\n",
    "\n",
    "# KERAS\n",
    "SEQUENCE_LENGTH = 300\n",
    "EPOCHS = 8\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# SENTIMENT\n",
    "POSITIVE = \"POSITIVE\"\n",
    "NEGATIVE = \"NEGATIVE\"\n",
    "NEUTRAL = \"NEUTRAL\"\n",
    "SENTIMENT_THRESHOLDS = (0.4, 0.7)\n",
    "\n",
    "# EXPORT\n",
    "KERAS_MODEL = \"model.h5\"\n",
    "WORD2VEC_MODEL = \"model.w2v\"\n",
    "TOKENIZER_MODEL = \"tokenizer.pkl\"\n",
    "ENCODER_MODEL = \"encoder.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1c3beecc618be68480b3d4f0de08d9d863da1dc1"
   },
   "source": [
    "### Read Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "563b3c44f1092dba0b853747b098e00509098cca"
   },
   "source": [
    "### Dataset details\n",
    "* **target**: the polarity of the tweet (0 = negative, 2 = neutral, 4 = positive)\n",
    "* **ids**: The id of the tweet ( 2087)\n",
    "* **date**: the date of the tweet (Sat May 16 23:58:44 UTC 2009)\n",
    "* **flag**: The query (lyx). If there is no query, then this value is NO_QUERY.\n",
    "* **user**: the user that tweeted (robotickilldozr)\n",
    "* **text**: the text of the tweet (Lyx is cool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "bba8f91cd70de4f5ea0fb0870ae2029b6e3dcc24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Open file: ../data/raw/training.1600000.processed.noemoticon.csv\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(\"..\",\"data\",\"raw\", \"training.1600000.processed.noemoticon.csv\")\n",
    "print(\"Open file:\", dataset_path)\n",
    "df = pd.read_csv(dataset_path, encoding =DATASET_ENCODING , names=DATASET_COLUMNS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "936d499c00c4f1648bc16ca9d283c3b39be7fb10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 1600000\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset size:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "7486ed895b813c5246f97b31b6162b0f65ff763b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3f9a7bb129e184967b13261fb5d253af451c75c5"
   },
   "source": [
    "### Map target label to String\n",
    "* **0** -> **NEGATIVE**\n",
    "* **2** -> **NEUTRAL**\n",
    "* **4** -> **POSITIVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "14074b59106cb9550440839e48b832223fc9502f"
   },
   "outputs": [],
   "source": [
    "decode_map = {0: \"NEGATIVE\", 2: \"NEUTRAL\", 4: \"POSITIVE\"}\n",
    "def decode_sentiment(label):\n",
    "    return decode_map[int(label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "4449d473187f647a195a6ac6986b009da32a7f4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 467 ms, sys: 5.3 ms, total: 472 ms\n",
      "Wall time: 470 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.target = df.target.apply(lambda x: decode_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "19eb327803192f31cce3512aacb232f4d6b38715"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Dataset labels distribuition')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_cnt = Counter(df.target)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.bar(target_cnt.keys(), target_cnt.values())\n",
    "plt.title(\"Dataset labels distribuition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4329b1573518b03e497213efa7676220734ebb4b"
   },
   "source": [
    "### Pre-Process dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "8aeee8b7b9ea11b749c7f91cd4787a7b50ed1a91"
   },
   "outputs": [],
   "source": [
    "stop_words = stopwords.words(\"english\")\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "649ebcb97969b9ac4301138783704bb3d7846a49"
   },
   "outputs": [],
   "source": [
    "def preprocess(text, stem=False):\n",
    "    # Remove link,user and special characters\n",
    "    text = re.sub(TEXT_CLEANING_RE, ' ', str(text).lower()).strip()\n",
    "    tokens = []\n",
    "    for token in text.split():\n",
    "        if token not in stop_words:\n",
    "            if stem:\n",
    "                tokens.append(stemmer.stem(token))\n",
    "            else:\n",
    "                tokens.append(token)\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "f7f3e77ab9291d14687c49e71ba9b2b1e3323432"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.6 s, sys: 239 ms, total: 35.9 s\n",
      "Wall time: 35.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df.text = df.text.apply(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f5f9714a8507409bbe780eebf2855a33e8e6ba37"
   },
   "source": [
    "### Split train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "d2b1179c968e3f3910c790ecf0c5b2cbb34b0e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN size: 1280000\n",
      "TEST size: 320000\n"
     ]
    }
   ],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=1-TRAIN_SIZE, random_state=42)\n",
    "print(\"TRAIN size:\", len(df_train))\n",
    "print(\"TEST size:\", len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f08a28aab2c3d16d8b9681a7d5d07587153a1cd6"
   },
   "source": [
    "### Word2Vec "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "2461bf564de1b4414841933d0c1d1bee5f5cc5a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.34 s, sys: 176 ms, total: 2.52 s\n",
      "Wall time: 2.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "documents = [_text.split() for _text in df_train.text] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "8e19b9f25801ba86420decc266d2b3e6fb44f1ea"
   },
   "outputs": [],
   "source": [
    "w2v_model = gensim.models.word2vec.Word2Vec(size=W2V_SIZE, \n",
    "                                            window=W2V_WINDOW, \n",
    "                                            min_count=W2V_MIN_COUNT, \n",
    "                                            workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "58d655af07653c594bec6bebcfb302a973b0ad9c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:33:10,170 : INFO : collecting all words and their counts\n",
      "2020-02-26 18:33:10,171 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2020-02-26 18:33:10,193 : INFO : PROGRESS: at sentence #10000, processed 72565 words, keeping 14005 word types\n",
      "2020-02-26 18:33:10,210 : INFO : PROGRESS: at sentence #20000, processed 144393 words, keeping 21587 word types\n",
      "2020-02-26 18:33:10,233 : INFO : PROGRESS: at sentence #30000, processed 215826 words, keeping 27541 word types\n",
      "2020-02-26 18:33:10,260 : INFO : PROGRESS: at sentence #40000, processed 288271 words, keeping 32764 word types\n",
      "2020-02-26 18:33:10,278 : INFO : PROGRESS: at sentence #50000, processed 359772 words, keeping 37587 word types\n",
      "2020-02-26 18:33:10,306 : INFO : PROGRESS: at sentence #60000, processed 431431 words, keeping 42198 word types\n",
      "2020-02-26 18:33:10,327 : INFO : PROGRESS: at sentence #70000, processed 503103 words, keeping 46458 word types\n",
      "2020-02-26 18:33:10,347 : INFO : PROGRESS: at sentence #80000, processed 575709 words, keeping 50476 word types\n",
      "2020-02-26 18:33:10,369 : INFO : PROGRESS: at sentence #90000, processed 647100 words, keeping 54140 word types\n",
      "2020-02-26 18:33:10,390 : INFO : PROGRESS: at sentence #100000, processed 718681 words, keeping 57777 word types\n",
      "2020-02-26 18:33:10,415 : INFO : PROGRESS: at sentence #110000, processed 790696 words, keeping 61207 word types\n",
      "2020-02-26 18:33:10,434 : INFO : PROGRESS: at sentence #120000, processed 863134 words, keeping 64583 word types\n",
      "2020-02-26 18:33:10,454 : INFO : PROGRESS: at sentence #130000, processed 935111 words, keeping 67865 word types\n",
      "2020-02-26 18:33:10,472 : INFO : PROGRESS: at sentence #140000, processed 1006668 words, keeping 70966 word types\n",
      "2020-02-26 18:33:10,491 : INFO : PROGRESS: at sentence #150000, processed 1078512 words, keeping 74119 word types\n",
      "2020-02-26 18:33:10,510 : INFO : PROGRESS: at sentence #160000, processed 1149914 words, keeping 77187 word types\n",
      "2020-02-26 18:33:10,528 : INFO : PROGRESS: at sentence #170000, processed 1222145 words, keeping 80267 word types\n",
      "2020-02-26 18:33:10,547 : INFO : PROGRESS: at sentence #180000, processed 1294708 words, keeping 83393 word types\n",
      "2020-02-26 18:33:10,566 : INFO : PROGRESS: at sentence #190000, processed 1367608 words, keeping 86329 word types\n",
      "2020-02-26 18:33:10,591 : INFO : PROGRESS: at sentence #200000, processed 1439469 words, keeping 89103 word types\n",
      "2020-02-26 18:33:10,613 : INFO : PROGRESS: at sentence #210000, processed 1512099 words, keeping 91840 word types\n",
      "2020-02-26 18:33:10,640 : INFO : PROGRESS: at sentence #220000, processed 1584149 words, keeping 94636 word types\n",
      "2020-02-26 18:33:10,659 : INFO : PROGRESS: at sentence #230000, processed 1656354 words, keeping 97353 word types\n",
      "2020-02-26 18:33:10,679 : INFO : PROGRESS: at sentence #240000, processed 1728573 words, keeping 99975 word types\n",
      "2020-02-26 18:33:10,698 : INFO : PROGRESS: at sentence #250000, processed 1801102 words, keeping 102594 word types\n",
      "2020-02-26 18:33:10,718 : INFO : PROGRESS: at sentence #260000, processed 1873103 words, keeping 105162 word types\n",
      "2020-02-26 18:33:10,738 : INFO : PROGRESS: at sentence #270000, processed 1945245 words, keeping 107626 word types\n",
      "2020-02-26 18:33:10,756 : INFO : PROGRESS: at sentence #280000, processed 2017163 words, keeping 110141 word types\n",
      "2020-02-26 18:33:10,781 : INFO : PROGRESS: at sentence #290000, processed 2089574 words, keeping 112539 word types\n",
      "2020-02-26 18:33:10,806 : INFO : PROGRESS: at sentence #300000, processed 2160996 words, keeping 114893 word types\n",
      "2020-02-26 18:33:10,826 : INFO : PROGRESS: at sentence #310000, processed 2232913 words, keeping 117298 word types\n",
      "2020-02-26 18:33:10,846 : INFO : PROGRESS: at sentence #320000, processed 2305039 words, keeping 119693 word types\n",
      "2020-02-26 18:33:10,866 : INFO : PROGRESS: at sentence #330000, processed 2377119 words, keeping 122131 word types\n",
      "2020-02-26 18:33:10,886 : INFO : PROGRESS: at sentence #340000, processed 2449370 words, keeping 124416 word types\n",
      "2020-02-26 18:33:10,906 : INFO : PROGRESS: at sentence #350000, processed 2521564 words, keeping 126669 word types\n",
      "2020-02-26 18:33:10,926 : INFO : PROGRESS: at sentence #360000, processed 2593681 words, keeping 128912 word types\n",
      "2020-02-26 18:33:10,945 : INFO : PROGRESS: at sentence #370000, processed 2665692 words, keeping 131135 word types\n",
      "2020-02-26 18:33:10,965 : INFO : PROGRESS: at sentence #380000, processed 2737859 words, keeping 133403 word types\n",
      "2020-02-26 18:33:10,984 : INFO : PROGRESS: at sentence #390000, processed 2809848 words, keeping 135551 word types\n",
      "2020-02-26 18:33:11,004 : INFO : PROGRESS: at sentence #400000, processed 2882438 words, keeping 137742 word types\n",
      "2020-02-26 18:33:11,023 : INFO : PROGRESS: at sentence #410000, processed 2954075 words, keeping 139909 word types\n",
      "2020-02-26 18:33:11,043 : INFO : PROGRESS: at sentence #420000, processed 3026247 words, keeping 142144 word types\n",
      "2020-02-26 18:33:11,064 : INFO : PROGRESS: at sentence #430000, processed 3098659 words, keeping 144364 word types\n",
      "2020-02-26 18:33:11,084 : INFO : PROGRESS: at sentence #440000, processed 3170663 words, keeping 146439 word types\n",
      "2020-02-26 18:33:11,104 : INFO : PROGRESS: at sentence #450000, processed 3243344 words, keeping 148526 word types\n",
      "2020-02-26 18:33:11,123 : INFO : PROGRESS: at sentence #460000, processed 3315466 words, keeping 150610 word types\n",
      "2020-02-26 18:33:11,143 : INFO : PROGRESS: at sentence #470000, processed 3388295 words, keeping 152737 word types\n",
      "2020-02-26 18:33:11,163 : INFO : PROGRESS: at sentence #480000, processed 3460120 words, keeping 154757 word types\n",
      "2020-02-26 18:33:11,182 : INFO : PROGRESS: at sentence #490000, processed 3531883 words, keeping 156825 word types\n",
      "2020-02-26 18:33:11,206 : INFO : PROGRESS: at sentence #500000, processed 3604217 words, keeping 158859 word types\n",
      "2020-02-26 18:33:11,226 : INFO : PROGRESS: at sentence #510000, processed 3676427 words, keeping 160852 word types\n",
      "2020-02-26 18:33:11,253 : INFO : PROGRESS: at sentence #520000, processed 3749045 words, keeping 162863 word types\n",
      "2020-02-26 18:33:11,273 : INFO : PROGRESS: at sentence #530000, processed 3821622 words, keeping 164929 word types\n",
      "2020-02-26 18:33:11,295 : INFO : PROGRESS: at sentence #540000, processed 3893627 words, keeping 166840 word types\n",
      "2020-02-26 18:33:11,331 : INFO : PROGRESS: at sentence #550000, processed 3965477 words, keeping 168799 word types\n",
      "2020-02-26 18:33:11,350 : INFO : PROGRESS: at sentence #560000, processed 4038050 words, keeping 170802 word types\n",
      "2020-02-26 18:33:11,372 : INFO : PROGRESS: at sentence #570000, processed 4110296 words, keeping 172760 word types\n",
      "2020-02-26 18:33:11,395 : INFO : PROGRESS: at sentence #580000, processed 4182385 words, keeping 174635 word types\n",
      "2020-02-26 18:33:11,423 : INFO : PROGRESS: at sentence #590000, processed 4254632 words, keeping 176470 word types\n",
      "2020-02-26 18:33:11,443 : INFO : PROGRESS: at sentence #600000, processed 4326859 words, keeping 178350 word types\n",
      "2020-02-26 18:33:11,464 : INFO : PROGRESS: at sentence #610000, processed 4399183 words, keeping 180290 word types\n",
      "2020-02-26 18:33:11,483 : INFO : PROGRESS: at sentence #620000, processed 4471343 words, keeping 182129 word types\n",
      "2020-02-26 18:33:11,505 : INFO : PROGRESS: at sentence #630000, processed 4543286 words, keeping 184005 word types\n",
      "2020-02-26 18:33:11,528 : INFO : PROGRESS: at sentence #640000, processed 4615780 words, keeping 185835 word types\n",
      "2020-02-26 18:33:11,547 : INFO : PROGRESS: at sentence #650000, processed 4688481 words, keeping 187705 word types\n",
      "2020-02-26 18:33:11,572 : INFO : PROGRESS: at sentence #660000, processed 4760481 words, keeping 189439 word types\n",
      "2020-02-26 18:33:11,592 : INFO : PROGRESS: at sentence #670000, processed 4833024 words, keeping 191232 word types\n",
      "2020-02-26 18:33:11,612 : INFO : PROGRESS: at sentence #680000, processed 4904516 words, keeping 193177 word types\n",
      "2020-02-26 18:33:11,632 : INFO : PROGRESS: at sentence #690000, processed 4976968 words, keeping 194960 word types\n",
      "2020-02-26 18:33:11,653 : INFO : PROGRESS: at sentence #700000, processed 5049412 words, keeping 196725 word types\n",
      "2020-02-26 18:33:11,672 : INFO : PROGRESS: at sentence #710000, processed 5121976 words, keeping 198516 word types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:33:11,691 : INFO : PROGRESS: at sentence #720000, processed 5193881 words, keeping 200325 word types\n",
      "2020-02-26 18:33:11,710 : INFO : PROGRESS: at sentence #730000, processed 5265467 words, keeping 202133 word types\n",
      "2020-02-26 18:33:11,729 : INFO : PROGRESS: at sentence #740000, processed 5337518 words, keeping 203818 word types\n",
      "2020-02-26 18:33:11,748 : INFO : PROGRESS: at sentence #750000, processed 5409321 words, keeping 205535 word types\n",
      "2020-02-26 18:33:11,767 : INFO : PROGRESS: at sentence #760000, processed 5481512 words, keeping 207282 word types\n",
      "2020-02-26 18:33:11,787 : INFO : PROGRESS: at sentence #770000, processed 5554093 words, keeping 209076 word types\n",
      "2020-02-26 18:33:11,806 : INFO : PROGRESS: at sentence #780000, processed 5625382 words, keeping 210805 word types\n",
      "2020-02-26 18:33:11,825 : INFO : PROGRESS: at sentence #790000, processed 5698066 words, keeping 212618 word types\n",
      "2020-02-26 18:33:11,845 : INFO : PROGRESS: at sentence #800000, processed 5770880 words, keeping 214374 word types\n",
      "2020-02-26 18:33:11,865 : INFO : PROGRESS: at sentence #810000, processed 5843418 words, keeping 216009 word types\n",
      "2020-02-26 18:33:11,887 : INFO : PROGRESS: at sentence #820000, processed 5915628 words, keeping 217804 word types\n",
      "2020-02-26 18:33:11,906 : INFO : PROGRESS: at sentence #830000, processed 5987499 words, keeping 219585 word types\n",
      "2020-02-26 18:33:11,926 : INFO : PROGRESS: at sentence #840000, processed 6058973 words, keeping 221344 word types\n",
      "2020-02-26 18:33:11,952 : INFO : PROGRESS: at sentence #850000, processed 6131125 words, keeping 223002 word types\n",
      "2020-02-26 18:33:11,971 : INFO : PROGRESS: at sentence #860000, processed 6202951 words, keeping 224643 word types\n",
      "2020-02-26 18:33:11,990 : INFO : PROGRESS: at sentence #870000, processed 6275461 words, keeping 226362 word types\n",
      "2020-02-26 18:33:12,009 : INFO : PROGRESS: at sentence #880000, processed 6347661 words, keeping 227986 word types\n",
      "2020-02-26 18:33:12,029 : INFO : PROGRESS: at sentence #890000, processed 6419806 words, keeping 229634 word types\n",
      "2020-02-26 18:33:12,048 : INFO : PROGRESS: at sentence #900000, processed 6491644 words, keeping 231389 word types\n",
      "2020-02-26 18:33:12,082 : INFO : PROGRESS: at sentence #910000, processed 6564022 words, keeping 233050 word types\n",
      "2020-02-26 18:33:12,102 : INFO : PROGRESS: at sentence #920000, processed 6636228 words, keeping 234686 word types\n",
      "2020-02-26 18:33:12,127 : INFO : PROGRESS: at sentence #930000, processed 6708573 words, keeping 236393 word types\n",
      "2020-02-26 18:33:12,149 : INFO : PROGRESS: at sentence #940000, processed 6779956 words, keeping 238052 word types\n",
      "2020-02-26 18:33:12,174 : INFO : PROGRESS: at sentence #950000, processed 6852599 words, keeping 239716 word types\n",
      "2020-02-26 18:33:12,194 : INFO : PROGRESS: at sentence #960000, processed 6924717 words, keeping 241354 word types\n",
      "2020-02-26 18:33:12,215 : INFO : PROGRESS: at sentence #970000, processed 6996992 words, keeping 242980 word types\n",
      "2020-02-26 18:33:12,237 : INFO : PROGRESS: at sentence #980000, processed 7068402 words, keeping 244646 word types\n",
      "2020-02-26 18:33:12,258 : INFO : PROGRESS: at sentence #990000, processed 7140346 words, keeping 246186 word types\n",
      "2020-02-26 18:33:12,281 : INFO : PROGRESS: at sentence #1000000, processed 7211757 words, keeping 247726 word types\n",
      "2020-02-26 18:33:12,305 : INFO : PROGRESS: at sentence #1010000, processed 7283267 words, keeping 249288 word types\n",
      "2020-02-26 18:33:12,324 : INFO : PROGRESS: at sentence #1020000, processed 7355299 words, keeping 250860 word types\n",
      "2020-02-26 18:33:12,343 : INFO : PROGRESS: at sentence #1030000, processed 7426918 words, keeping 252366 word types\n",
      "2020-02-26 18:33:12,362 : INFO : PROGRESS: at sentence #1040000, processed 7498815 words, keeping 253930 word types\n",
      "2020-02-26 18:33:12,380 : INFO : PROGRESS: at sentence #1050000, processed 7570499 words, keeping 255471 word types\n",
      "2020-02-26 18:33:12,400 : INFO : PROGRESS: at sentence #1060000, processed 7643251 words, keeping 257035 word types\n",
      "2020-02-26 18:33:12,419 : INFO : PROGRESS: at sentence #1070000, processed 7714721 words, keeping 258509 word types\n",
      "2020-02-26 18:33:12,439 : INFO : PROGRESS: at sentence #1080000, processed 7787371 words, keeping 260071 word types\n",
      "2020-02-26 18:33:12,460 : INFO : PROGRESS: at sentence #1090000, processed 7859336 words, keeping 261683 word types\n",
      "2020-02-26 18:33:12,481 : INFO : PROGRESS: at sentence #1100000, processed 7932029 words, keeping 263278 word types\n",
      "2020-02-26 18:33:12,509 : INFO : PROGRESS: at sentence #1110000, processed 8004146 words, keeping 264800 word types\n",
      "2020-02-26 18:33:12,535 : INFO : PROGRESS: at sentence #1120000, processed 8075880 words, keeping 266309 word types\n",
      "2020-02-26 18:33:12,562 : INFO : PROGRESS: at sentence #1130000, processed 8148163 words, keeping 267826 word types\n",
      "2020-02-26 18:33:12,582 : INFO : PROGRESS: at sentence #1140000, processed 8220487 words, keeping 269391 word types\n",
      "2020-02-26 18:33:12,605 : INFO : PROGRESS: at sentence #1150000, processed 8292498 words, keeping 270894 word types\n",
      "2020-02-26 18:33:12,626 : INFO : PROGRESS: at sentence #1160000, processed 8363838 words, keeping 272400 word types\n",
      "2020-02-26 18:33:12,655 : INFO : PROGRESS: at sentence #1170000, processed 8435510 words, keeping 273970 word types\n",
      "2020-02-26 18:33:12,678 : INFO : PROGRESS: at sentence #1180000, processed 8507795 words, keeping 275521 word types\n",
      "2020-02-26 18:33:12,701 : INFO : PROGRESS: at sentence #1190000, processed 8579080 words, keeping 277007 word types\n",
      "2020-02-26 18:33:12,720 : INFO : PROGRESS: at sentence #1200000, processed 8650606 words, keeping 278457 word types\n",
      "2020-02-26 18:33:12,746 : INFO : PROGRESS: at sentence #1210000, processed 8721893 words, keeping 279959 word types\n",
      "2020-02-26 18:33:12,766 : INFO : PROGRESS: at sentence #1220000, processed 8793795 words, keeping 281427 word types\n",
      "2020-02-26 18:33:12,785 : INFO : PROGRESS: at sentence #1230000, processed 8865726 words, keeping 282981 word types\n",
      "2020-02-26 18:33:12,805 : INFO : PROGRESS: at sentence #1240000, processed 8938173 words, keeping 284542 word types\n",
      "2020-02-26 18:33:12,825 : INFO : PROGRESS: at sentence #1250000, processed 9010842 words, keeping 286064 word types\n",
      "2020-02-26 18:33:12,845 : INFO : PROGRESS: at sentence #1260000, processed 9083261 words, keeping 287521 word types\n",
      "2020-02-26 18:33:12,865 : INFO : PROGRESS: at sentence #1270000, processed 9155616 words, keeping 288987 word types\n",
      "2020-02-26 18:33:12,884 : INFO : collected 290418 word types from a corpus of 9227204 raw words and 1280000 sentences\n",
      "2020-02-26 18:33:12,884 : INFO : Loading a fresh vocabulary\n",
      "2020-02-26 18:33:13,038 : INFO : effective_min_count=10 retains 30369 unique words (10% of original 290418, drops 260049)\n",
      "2020-02-26 18:33:13,038 : INFO : effective_min_count=10 leaves 8780739 word corpus (95% of original 9227204, drops 446465)\n",
      "2020-02-26 18:33:13,130 : INFO : deleting the raw counts dictionary of 290418 items\n",
      "2020-02-26 18:33:13,137 : INFO : sample=0.001 downsamples 45 most-common words\n",
      "2020-02-26 18:33:13,138 : INFO : downsampling leaves estimated 8222658 word corpus (93.6% of prior 8780739)\n",
      "2020-02-26 18:33:13,215 : INFO : estimated required memory for 30369 words and 300 dimensions: 88070100 bytes\n",
      "2020-02-26 18:33:13,216 : INFO : resetting layer weights\n"
     ]
    }
   ],
   "source": [
    "w2v_model.build_vocab(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "72a5628ca81fd4b8983c12d93ae0bf950b86b6ae",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 30369\n"
     ]
    }
   ],
   "source": [
    "words = w2v_model.wv.vocab.keys()\n",
    "vocab_size = len(words)\n",
    "print(\"Vocab size\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "68c3e4a5ba07cac3dee67f78ecdd1404c7f83f14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:34:17,925 : INFO : training model with 8 workers on 30369 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=7\n",
      "2020-02-26 18:34:18,961 : INFO : EPOCH 1 - PROGRESS: at 8.36% examples, 679931 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:34:19,974 : INFO : EPOCH 1 - PROGRESS: at 17.89% examples, 726808 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:20,979 : INFO : EPOCH 1 - PROGRESS: at 26.88% examples, 730080 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:22,002 : INFO : EPOCH 1 - PROGRESS: at 36.40% examples, 739250 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:23,028 : INFO : EPOCH 1 - PROGRESS: at 46.02% examples, 745976 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:24,029 : INFO : EPOCH 1 - PROGRESS: at 55.10% examples, 746270 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:25,057 : INFO : EPOCH 1 - PROGRESS: at 64.73% examples, 749868 words/s, in_qsize 12, out_qsize 3\n",
      "2020-02-26 18:34:26,090 : INFO : EPOCH 1 - PROGRESS: at 74.59% examples, 754390 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:27,108 : INFO : EPOCH 1 - PROGRESS: at 84.37% examples, 757988 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:28,121 : INFO : EPOCH 1 - PROGRESS: at 93.70% examples, 757782 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:34:28,703 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:34:28,704 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:34:28,705 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:34:28,707 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:34:28,718 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:34:28,731 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:34:28,734 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:34:28,742 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:34:28,743 : INFO : EPOCH - 1 : training on 9227204 raw words (8223248 effective words) took 10.8s, 762023 effective words/s\n",
      "2020-02-26 18:34:29,754 : INFO : EPOCH 2 - PROGRESS: at 8.90% examples, 729474 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:30,758 : INFO : EPOCH 2 - PROGRESS: at 18.87% examples, 773070 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:31,769 : INFO : EPOCH 2 - PROGRESS: at 27.42% examples, 747308 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:32,778 : INFO : EPOCH 2 - PROGRESS: at 36.83% examples, 752559 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:33,803 : INFO : EPOCH 2 - PROGRESS: at 45.70% examples, 744285 words/s, in_qsize 13, out_qsize 4\n",
      "2020-02-26 18:34:34,804 : INFO : EPOCH 2 - PROGRESS: at 55.42% examples, 753832 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:35,807 : INFO : EPOCH 2 - PROGRESS: at 64.08% examples, 747630 words/s, in_qsize 16, out_qsize 4\n",
      "2020-02-26 18:34:36,808 : INFO : EPOCH 2 - PROGRESS: at 73.62% examples, 752085 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:34:37,813 : INFO : EPOCH 2 - PROGRESS: at 83.51% examples, 758044 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:38,820 : INFO : EPOCH 2 - PROGRESS: at 92.94% examples, 759194 words/s, in_qsize 15, out_qsize 1\n",
      "2020-02-26 18:34:39,482 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:34:39,486 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:34:39,488 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:34:39,490 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:34:39,497 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:34:39,516 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:34:39,522 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:34:39,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:34:39,530 : INFO : EPOCH - 2 : training on 9227204 raw words (8222482 effective words) took 10.8s, 762991 effective words/s\n",
      "2020-02-26 18:34:40,554 : INFO : EPOCH 3 - PROGRESS: at 9.12% examples, 738941 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:41,563 : INFO : EPOCH 3 - PROGRESS: at 18.43% examples, 748774 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:34:42,571 : INFO : EPOCH 3 - PROGRESS: at 27.64% examples, 749673 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:43,597 : INFO : EPOCH 3 - PROGRESS: at 36.94% examples, 748941 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:44,610 : INFO : EPOCH 3 - PROGRESS: at 46.57% examples, 755752 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:45,638 : INFO : EPOCH 3 - PROGRESS: at 55.97% examples, 755504 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:46,657 : INFO : EPOCH 3 - PROGRESS: at 65.72% examples, 759969 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:47,689 : INFO : EPOCH 3 - PROGRESS: at 75.14% examples, 758829 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:48,693 : INFO : EPOCH 3 - PROGRESS: at 84.58% examples, 760251 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:49,715 : INFO : EPOCH 3 - PROGRESS: at 93.59% examples, 756513 words/s, in_qsize 13, out_qsize 6\n",
      "2020-02-26 18:34:50,268 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:34:50,272 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:34:50,277 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:34:50,286 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:34:50,305 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:34:50,307 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:34:50,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:34:50,319 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:34:50,320 : INFO : EPOCH - 3 : training on 9227204 raw words (8223058 effective words) took 10.8s, 762898 effective words/s\n",
      "2020-02-26 18:34:51,343 : INFO : EPOCH 4 - PROGRESS: at 8.90% examples, 723049 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:52,352 : INFO : EPOCH 4 - PROGRESS: at 18.32% examples, 745267 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:34:53,369 : INFO : EPOCH 4 - PROGRESS: at 27.86% examples, 754012 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:54,371 : INFO : EPOCH 4 - PROGRESS: at 36.07% examples, 734587 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:34:55,380 : INFO : EPOCH 4 - PROGRESS: at 45.26% examples, 737677 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:34:56,381 : INFO : EPOCH 4 - PROGRESS: at 54.89% examples, 746650 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:34:57,383 : INFO : EPOCH 4 - PROGRESS: at 64.19% examples, 749259 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:34:58,402 : INFO : EPOCH 4 - PROGRESS: at 73.73% examples, 751661 words/s, in_qsize 12, out_qsize 3\n",
      "2020-02-26 18:34:59,424 : INFO : EPOCH 4 - PROGRESS: at 82.96% examples, 750440 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:00,432 : INFO : EPOCH 4 - PROGRESS: at 91.74% examples, 746915 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:01,345 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:01,360 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:01,375 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:01,383 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:01,395 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:01,399 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:01,412 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:01,421 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:01,422 : INFO : EPOCH - 4 : training on 9227204 raw words (8221131 effective words) took 11.1s, 741419 effective words/s\n",
      "2020-02-26 18:35:02,449 : INFO : EPOCH 5 - PROGRESS: at 8.15% examples, 657773 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:35:03,451 : INFO : EPOCH 5 - PROGRESS: at 17.35% examples, 706329 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:04,460 : INFO : EPOCH 5 - PROGRESS: at 26.34% examples, 715140 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:05,462 : INFO : EPOCH 5 - PROGRESS: at 35.86% examples, 731971 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:06,466 : INFO : EPOCH 5 - PROGRESS: at 45.81% examples, 748813 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:07,476 : INFO : EPOCH 5 - PROGRESS: at 55.32% examples, 753466 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:08,478 : INFO : EPOCH 5 - PROGRESS: at 64.40% examples, 752520 words/s, in_qsize 15, out_qsize 2\n",
      "2020-02-26 18:35:09,489 : INFO : EPOCH 5 - PROGRESS: at 74.16% examples, 757607 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:10,493 : INFO : EPOCH 5 - PROGRESS: at 83.72% examples, 760174 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:11,537 : INFO : EPOCH 5 - PROGRESS: at 92.94% examples, 756460 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:12,243 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:12,245 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:12,247 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:12,248 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:12,261 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:12,262 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:12,278 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:12,280 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:12,281 : INFO : EPOCH - 5 : training on 9227204 raw words (8222949 effective words) took 10.8s, 758042 effective words/s\n",
      "2020-02-26 18:35:13,301 : INFO : EPOCH 6 - PROGRESS: at 8.58% examples, 698223 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:14,302 : INFO : EPOCH 6 - PROGRESS: at 17.78% examples, 727263 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:15,305 : INFO : EPOCH 6 - PROGRESS: at 26.56% examples, 724756 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:16,305 : INFO : EPOCH 6 - PROGRESS: at 36.18% examples, 741704 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:17,306 : INFO : EPOCH 6 - PROGRESS: at 45.81% examples, 751652 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:18,307 : INFO : EPOCH 6 - PROGRESS: at 55.21% examples, 755575 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:19,330 : INFO : EPOCH 6 - PROGRESS: at 64.95% examples, 759731 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:20,334 : INFO : EPOCH 6 - PROGRESS: at 74.48% examples, 762301 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:21,338 : INFO : EPOCH 6 - PROGRESS: at 84.15% examples, 765367 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:35:22,374 : INFO : EPOCH 6 - PROGRESS: at 93.92% examples, 766178 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:22,987 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:23,000 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:23,008 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:23,018 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:23,019 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:23,024 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:23,044 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:23,045 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:23,046 : INFO : EPOCH - 6 : training on 9227204 raw words (8223013 effective words) took 10.8s, 764742 effective words/s\n",
      "2020-02-26 18:35:24,072 : INFO : EPOCH 7 - PROGRESS: at 7.60% examples, 614162 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:35:25,093 : INFO : EPOCH 7 - PROGRESS: at 17.35% examples, 699517 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:26,096 : INFO : EPOCH 7 - PROGRESS: at 26.34% examples, 712219 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:27,119 : INFO : EPOCH 7 - PROGRESS: at 35.10% examples, 710397 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:35:28,142 : INFO : EPOCH 7 - PROGRESS: at 44.07% examples, 712903 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:29,143 : INFO : EPOCH 7 - PROGRESS: at 53.27% examples, 720151 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:30,160 : INFO : EPOCH 7 - PROGRESS: at 62.89% examples, 728659 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:31,168 : INFO : EPOCH 7 - PROGRESS: at 71.67% examples, 727096 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:35:32,209 : INFO : EPOCH 7 - PROGRESS: at 81.45% examples, 731912 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:33,229 : INFO : EPOCH 7 - PROGRESS: at 90.65% examples, 732979 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:34,105 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:34,121 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:34,125 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:34,135 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:34,141 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:34,161 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:34,163 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:34,164 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:34,165 : INFO : EPOCH - 7 : training on 9227204 raw words (8223293 effective words) took 11.1s, 740213 effective words/s\n",
      "2020-02-26 18:35:35,187 : INFO : EPOCH 8 - PROGRESS: at 8.15% examples, 660518 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:36,220 : INFO : EPOCH 8 - PROGRESS: at 17.13% examples, 688336 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:37,228 : INFO : EPOCH 8 - PROGRESS: at 26.67% examples, 717650 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:35:38,236 : INFO : EPOCH 8 - PROGRESS: at 35.97% examples, 728191 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:39,259 : INFO : EPOCH 8 - PROGRESS: at 44.83% examples, 725451 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:40,284 : INFO : EPOCH 8 - PROGRESS: at 54.03% examples, 727747 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:35:41,295 : INFO : EPOCH 8 - PROGRESS: at 63.87% examples, 738337 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:42,307 : INFO : EPOCH 8 - PROGRESS: at 72.32% examples, 731827 words/s, in_qsize 10, out_qsize 5\n",
      "2020-02-26 18:35:43,325 : INFO : EPOCH 8 - PROGRESS: at 81.66% examples, 734153 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:44,350 : INFO : EPOCH 8 - PROGRESS: at 90.54% examples, 731947 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:45,362 : INFO : EPOCH 8 - PROGRESS: at 99.01% examples, 727776 words/s, in_qsize 9, out_qsize 1\n",
      "2020-02-26 18:35:45,370 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:45,374 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:45,374 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:45,397 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:45,404 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:45,406 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:45,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:45,417 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:45,418 : INFO : EPOCH - 8 : training on 9227204 raw words (8222838 effective words) took 11.2s, 731370 effective words/s\n",
      "2020-02-26 18:35:46,457 : INFO : EPOCH 9 - PROGRESS: at 8.58% examples, 683938 words/s, in_qsize 12, out_qsize 3\n",
      "2020-02-26 18:35:47,464 : INFO : EPOCH 9 - PROGRESS: at 18.11% examples, 730765 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:35:48,480 : INFO : EPOCH 9 - PROGRESS: at 27.53% examples, 741395 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:35:49,489 : INFO : EPOCH 9 - PROGRESS: at 37.05% examples, 750263 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:50,507 : INFO : EPOCH 9 - PROGRESS: at 46.89% examples, 759413 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:51,537 : INFO : EPOCH 9 - PROGRESS: at 56.73% examples, 764163 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:52,543 : INFO : EPOCH 9 - PROGRESS: at 64.84% examples, 749911 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:53,551 : INFO : EPOCH 9 - PROGRESS: at 73.51% examples, 744618 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:35:54,572 : INFO : EPOCH 9 - PROGRESS: at 82.96% examples, 746163 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:55,581 : INFO : EPOCH 9 - PROGRESS: at 91.42% examples, 740437 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:35:56,375 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:35:56,388 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:35:56,393 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:35:56,399 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:35:56,403 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:35:56,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:35:56,419 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:35:56,426 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:35:56,427 : INFO : EPOCH - 9 : training on 9227204 raw words (8221582 effective words) took 11.0s, 747555 effective words/s\n",
      "2020-02-26 18:35:57,462 : INFO : EPOCH 10 - PROGRESS: at 9.23% examples, 738295 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:58,498 : INFO : EPOCH 10 - PROGRESS: at 18.54% examples, 738872 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:35:59,543 : INFO : EPOCH 10 - PROGRESS: at 27.10% examples, 716846 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:00,562 : INFO : EPOCH 10 - PROGRESS: at 36.83% examples, 734203 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:01,565 : INFO : EPOCH 10 - PROGRESS: at 46.13% examples, 739950 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:02,595 : INFO : EPOCH 10 - PROGRESS: at 54.99% examples, 734873 words/s, in_qsize 16, out_qsize 7\n",
      "2020-02-26 18:36:03,627 : INFO : EPOCH 10 - PROGRESS: at 65.06% examples, 744582 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:04,639 : INFO : EPOCH 10 - PROGRESS: at 74.59% examples, 748267 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:05,641 : INFO : EPOCH 10 - PROGRESS: at 84.05% examples, 751056 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:06,652 : INFO : EPOCH 10 - PROGRESS: at 93.26% examples, 750770 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:07,318 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:36:07,321 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:36:07,326 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:36:07,332 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:36:07,348 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:36:07,358 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:36:07,367 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:36:07,376 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:36:07,377 : INFO : EPOCH - 10 : training on 9227204 raw words (8222702 effective words) took 10.9s, 751593 effective words/s\n",
      "2020-02-26 18:36:08,391 : INFO : EPOCH 11 - PROGRESS: at 9.12% examples, 744272 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:09,391 : INFO : EPOCH 11 - PROGRESS: at 18.65% examples, 763902 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:10,422 : INFO : EPOCH 11 - PROGRESS: at 28.72% examples, 777631 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:11,435 : INFO : EPOCH 11 - PROGRESS: at 38.14% examples, 774526 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:12,451 : INFO : EPOCH 11 - PROGRESS: at 48.08% examples, 780947 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:13,479 : INFO : EPOCH 11 - PROGRESS: at 57.48% examples, 776442 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:14,483 : INFO : EPOCH 11 - PROGRESS: at 66.80% examples, 774513 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:15,489 : INFO : EPOCH 11 - PROGRESS: at 75.89% examples, 770678 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:16,506 : INFO : EPOCH 11 - PROGRESS: at 85.23% examples, 768763 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:17,506 : INFO : EPOCH 11 - PROGRESS: at 94.36% examples, 766624 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:18,037 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:36:18,039 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:36:18,046 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:36:18,066 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:36:18,072 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:36:18,073 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:36:18,078 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:36:18,088 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:36:18,088 : INFO : EPOCH - 11 : training on 9227204 raw words (8223346 effective words) took 10.7s, 768295 effective words/s\n",
      "2020-02-26 18:36:19,123 : INFO : EPOCH 12 - PROGRESS: at 9.01% examples, 720763 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:20,183 : INFO : EPOCH 12 - PROGRESS: at 18.65% examples, 734183 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:21,189 : INFO : EPOCH 12 - PROGRESS: at 27.64% examples, 734451 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:22,192 : INFO : EPOCH 12 - PROGRESS: at 36.51% examples, 732826 words/s, in_qsize 15, out_qsize 1\n",
      "2020-02-26 18:36:23,202 : INFO : EPOCH 12 - PROGRESS: at 45.37% examples, 730962 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:24,219 : INFO : EPOCH 12 - PROGRESS: at 54.89% examples, 737598 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:25,233 : INFO : EPOCH 12 - PROGRESS: at 64.08% examples, 739009 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:26,262 : INFO : EPOCH 12 - PROGRESS: at 73.41% examples, 739680 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:27,271 : INFO : EPOCH 12 - PROGRESS: at 83.07% examples, 744676 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:28,280 : INFO : EPOCH 12 - PROGRESS: at 93.05% examples, 751393 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:28,902 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:36:28,910 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:36:28,913 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:36:28,915 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:36:28,922 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:36:28,946 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:36:28,948 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:36:28,950 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:36:28,951 : INFO : EPOCH - 12 : training on 9227204 raw words (8222477 effective words) took 10.9s, 757529 effective words/s\n",
      "2020-02-26 18:36:29,967 : INFO : EPOCH 13 - PROGRESS: at 8.25% examples, 674061 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:36:30,974 : INFO : EPOCH 13 - PROGRESS: at 18.11% examples, 739198 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:32,000 : INFO : EPOCH 13 - PROGRESS: at 27.96% examples, 756460 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:36:33,026 : INFO : EPOCH 13 - PROGRESS: at 36.94% examples, 747635 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:36:34,038 : INFO : EPOCH 13 - PROGRESS: at 46.89% examples, 760001 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:35,042 : INFO : EPOCH 13 - PROGRESS: at 56.51% examples, 764861 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:36,046 : INFO : EPOCH 13 - PROGRESS: at 65.72% examples, 763368 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:36:37,059 : INFO : EPOCH 13 - PROGRESS: at 75.35% examples, 765808 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:38,092 : INFO : EPOCH 13 - PROGRESS: at 84.04% examples, 757210 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:39,108 : INFO : EPOCH 13 - PROGRESS: at 92.83% examples, 752403 words/s, in_qsize 11, out_qsize 4\n",
      "2020-02-26 18:36:39,793 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:36:39,796 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:36:39,799 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:36:39,800 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:36:39,813 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:36:39,814 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:36:39,833 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:36:39,835 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:36:39,835 : INFO : EPOCH - 13 : training on 9227204 raw words (8222742 effective words) took 10.9s, 756264 effective words/s\n",
      "2020-02-26 18:36:40,853 : INFO : EPOCH 14 - PROGRESS: at 8.47% examples, 688146 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:41,943 : INFO : EPOCH 14 - PROGRESS: at 18.00% examples, 704484 words/s, in_qsize 14, out_qsize 4\n",
      "2020-02-26 18:36:42,982 : INFO : EPOCH 14 - PROGRESS: at 27.64% examples, 724077 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:43,989 : INFO : EPOCH 14 - PROGRESS: at 36.61% examples, 726586 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:45,015 : INFO : EPOCH 14 - PROGRESS: at 45.81% examples, 728857 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:46,025 : INFO : EPOCH 14 - PROGRESS: at 54.78% examples, 729487 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:47,031 : INFO : EPOCH 14 - PROGRESS: at 63.87% examples, 731519 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:48,042 : INFO : EPOCH 14 - PROGRESS: at 72.43% examples, 727061 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:36:49,061 : INFO : EPOCH 14 - PROGRESS: at 81.12% examples, 724019 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:50,067 : INFO : EPOCH 14 - PROGRESS: at 90.11% examples, 725020 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:36:51,087 : INFO : EPOCH 14 - PROGRESS: at 99.24% examples, 725858 words/s, in_qsize 7, out_qsize 1\n",
      "2020-02-26 18:36:51,089 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:36:51,097 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:36:51,100 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:36:51,103 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:36:51,114 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:36:51,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:36:51,118 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:36:51,127 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:36:51,128 : INFO : EPOCH - 14 : training on 9227204 raw words (8223490 effective words) took 11.3s, 728754 effective words/s\n",
      "2020-02-26 18:36:52,183 : INFO : EPOCH 15 - PROGRESS: at 8.90% examples, 698702 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:53,186 : INFO : EPOCH 15 - PROGRESS: at 18.11% examples, 725892 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:36:54,194 : INFO : EPOCH 15 - PROGRESS: at 27.42% examples, 737383 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:55,219 : INFO : EPOCH 15 - PROGRESS: at 37.16% examples, 748587 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:56,233 : INFO : EPOCH 15 - PROGRESS: at 45.59% examples, 736014 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:57,242 : INFO : EPOCH 15 - PROGRESS: at 53.92% examples, 726746 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:58,247 : INFO : EPOCH 15 - PROGRESS: at 61.93% examples, 716755 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:36:59,262 : INFO : EPOCH 15 - PROGRESS: at 69.83% examples, 707199 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:37:00,299 : INFO : EPOCH 15 - PROGRESS: at 78.84% examples, 707891 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:01,315 : INFO : EPOCH 15 - PROGRESS: at 87.62% examples, 708071 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:02,327 : INFO : EPOCH 15 - PROGRESS: at 96.64% examples, 710045 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:02,592 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:02,614 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:02,616 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:02,617 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:02,628 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:02,638 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:02,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:02,645 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:02,645 : INFO : EPOCH - 15 : training on 9227204 raw words (8222876 effective words) took 11.5s, 714523 effective words/s\n",
      "2020-02-26 18:37:03,669 : INFO : EPOCH 16 - PROGRESS: at 8.69% examples, 702028 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:04,686 : INFO : EPOCH 16 - PROGRESS: at 17.89% examples, 723058 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:05,719 : INFO : EPOCH 16 - PROGRESS: at 26.78% examples, 717773 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:06,746 : INFO : EPOCH 16 - PROGRESS: at 36.07% examples, 724812 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:07,759 : INFO : EPOCH 16 - PROGRESS: at 44.83% examples, 722276 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:08,765 : INFO : EPOCH 16 - PROGRESS: at 53.92% examples, 725975 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:09,798 : INFO : EPOCH 16 - PROGRESS: at 62.90% examples, 724545 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:10,814 : INFO : EPOCH 16 - PROGRESS: at 71.78% examples, 723751 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:37:11,823 : INFO : EPOCH 16 - PROGRESS: at 81.23% examples, 728621 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:12,842 : INFO : EPOCH 16 - PROGRESS: at 90.65% examples, 731821 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:13,742 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:13,752 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:13,766 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:13,768 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:13,777 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:13,787 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:13,794 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:13,798 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:13,798 : INFO : EPOCH - 16 : training on 9227204 raw words (8222871 effective words) took 11.1s, 737839 effective words/s\n",
      "2020-02-26 18:37:14,808 : INFO : EPOCH 17 - PROGRESS: at 8.58% examples, 703257 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:15,814 : INFO : EPOCH 17 - PROGRESS: at 18.54% examples, 758957 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:37:16,854 : INFO : EPOCH 17 - PROGRESS: at 28.18% examples, 760273 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:17,857 : INFO : EPOCH 17 - PROGRESS: at 37.81% examples, 767820 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:37:18,860 : INFO : EPOCH 17 - PROGRESS: at 47.43% examples, 772340 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:19,867 : INFO : EPOCH 17 - PROGRESS: at 56.95% examples, 773502 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:20,885 : INFO : EPOCH 17 - PROGRESS: at 66.25% examples, 770517 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:21,893 : INFO : EPOCH 17 - PROGRESS: at 76.66% examples, 780229 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:37:22,898 : INFO : EPOCH 17 - PROGRESS: at 86.42% examples, 782121 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:23,909 : INFO : EPOCH 17 - PROGRESS: at 96.10% examples, 782329 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:24,221 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:24,236 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:24,241 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:24,250 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:24,264 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:24,267 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:24,271 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:24,275 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:24,276 : INFO : EPOCH - 17 : training on 9227204 raw words (8224225 effective words) took 10.5s, 785578 effective words/s\n",
      "2020-02-26 18:37:25,301 : INFO : EPOCH 18 - PROGRESS: at 8.47% examples, 683261 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:26,305 : INFO : EPOCH 18 - PROGRESS: at 17.57% examples, 713737 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:27,306 : INFO : EPOCH 18 - PROGRESS: at 26.99% examples, 734052 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:28,306 : INFO : EPOCH 18 - PROGRESS: at 36.07% examples, 737572 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:29,347 : INFO : EPOCH 18 - PROGRESS: at 46.03% examples, 747697 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:37:30,358 : INFO : EPOCH 18 - PROGRESS: at 55.42% examples, 751028 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:37:31,377 : INFO : EPOCH 18 - PROGRESS: at 64.95% examples, 753637 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:32,383 : INFO : EPOCH 18 - PROGRESS: at 74.16% examples, 753442 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:33,413 : INFO : EPOCH 18 - PROGRESS: at 83.83% examples, 755262 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:34,418 : INFO : EPOCH 18 - PROGRESS: at 93.26% examples, 756792 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:35,089 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:35,096 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:35,097 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:35,101 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:35,105 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:35,128 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:35,131 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:35,136 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:35,136 : INFO : EPOCH - 18 : training on 9227204 raw words (8222857 effective words) took 10.9s, 757675 effective words/s\n",
      "2020-02-26 18:37:36,166 : INFO : EPOCH 19 - PROGRESS: at 9.12% examples, 732675 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:37,177 : INFO : EPOCH 19 - PROGRESS: at 18.43% examples, 744889 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:38,195 : INFO : EPOCH 19 - PROGRESS: at 27.53% examples, 741877 words/s, in_qsize 12, out_qsize 3\n",
      "2020-02-26 18:37:39,198 : INFO : EPOCH 19 - PROGRESS: at 37.16% examples, 753750 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:37:40,203 : INFO : EPOCH 19 - PROGRESS: at 46.57% examples, 757304 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:41,213 : INFO : EPOCH 19 - PROGRESS: at 55.75% examples, 756167 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:37:42,219 : INFO : EPOCH 19 - PROGRESS: at 65.72% examples, 764424 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:43,229 : INFO : EPOCH 19 - PROGRESS: at 75.14% examples, 764800 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:44,234 : INFO : EPOCH 19 - PROGRESS: at 84.80% examples, 767382 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:45,263 : INFO : EPOCH 19 - PROGRESS: at 94.14% examples, 765005 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:45,853 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:45,863 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:45,869 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:45,871 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:45,910 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:45,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:45,915 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:45,921 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:45,922 : INFO : EPOCH - 19 : training on 9227204 raw words (8222809 effective words) took 10.8s, 762999 effective words/s\n",
      "2020-02-26 18:37:46,953 : INFO : EPOCH 20 - PROGRESS: at 8.04% examples, 647402 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:47,962 : INFO : EPOCH 20 - PROGRESS: at 17.13% examples, 694046 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:37:48,981 : INFO : EPOCH 20 - PROGRESS: at 25.37% examples, 684328 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:37:49,986 : INFO : EPOCH 20 - PROGRESS: at 33.81% examples, 686063 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:51,022 : INFO : EPOCH 20 - PROGRESS: at 42.46% examples, 686458 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:52,042 : INFO : EPOCH 20 - PROGRESS: at 51.10% examples, 688534 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:53,050 : INFO : EPOCH 20 - PROGRESS: at 60.63% examples, 701315 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:54,082 : INFO : EPOCH 20 - PROGRESS: at 70.27% examples, 709702 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:55,083 : INFO : EPOCH 20 - PROGRESS: at 79.38% examples, 713833 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:37:56,105 : INFO : EPOCH 20 - PROGRESS: at 88.70% examples, 717437 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:37:57,116 : INFO : EPOCH 20 - PROGRESS: at 98.25% examples, 722643 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:37:57,215 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:37:57,217 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:37:57,225 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:37:57,237 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:37:57,246 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:37:57,250 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:37:57,252 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:37:57,263 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:37:57,264 : INFO : EPOCH - 20 : training on 9227204 raw words (8223481 effective words) took 11.3s, 725882 effective words/s\n",
      "2020-02-26 18:37:58,299 : INFO : EPOCH 21 - PROGRESS: at 9.01% examples, 730504 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:37:59,300 : INFO : EPOCH 21 - PROGRESS: at 18.97% examples, 774497 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:00,317 : INFO : EPOCH 21 - PROGRESS: at 28.18% examples, 764524 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:01,337 : INFO : EPOCH 21 - PROGRESS: at 38.46% examples, 781037 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:02,365 : INFO : EPOCH 21 - PROGRESS: at 48.19% examples, 780775 words/s, in_qsize 14, out_qsize 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:38:03,368 : INFO : EPOCH 21 - PROGRESS: at 57.81% examples, 782416 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:04,368 : INFO : EPOCH 21 - PROGRESS: at 67.24% examples, 781300 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:05,371 : INFO : EPOCH 21 - PROGRESS: at 76.77% examples, 781354 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:06,381 : INFO : EPOCH 21 - PROGRESS: at 86.10% examples, 778694 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:07,388 : INFO : EPOCH 21 - PROGRESS: at 95.66% examples, 778637 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:07,786 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:38:07,793 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:38:07,799 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:38:07,801 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:38:07,802 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:38:07,817 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:38:07,830 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:38:07,833 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:38:07,834 : INFO : EPOCH - 21 : training on 9227204 raw words (8221877 effective words) took 10.5s, 779612 effective words/s\n",
      "2020-02-26 18:38:08,898 : INFO : EPOCH 22 - PROGRESS: at 9.01% examples, 700053 words/s, in_qsize 13, out_qsize 3\n",
      "2020-02-26 18:38:09,899 : INFO : EPOCH 22 - PROGRESS: at 17.68% examples, 705705 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:10,939 : INFO : EPOCH 22 - PROGRESS: at 26.67% examples, 707390 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:11,942 : INFO : EPOCH 22 - PROGRESS: at 36.18% examples, 725650 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:12,964 : INFO : EPOCH 22 - PROGRESS: at 45.05% examples, 723391 words/s, in_qsize 15, out_qsize 2\n",
      "2020-02-26 18:38:13,975 : INFO : EPOCH 22 - PROGRESS: at 55.42% examples, 743625 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:14,981 : INFO : EPOCH 22 - PROGRESS: at 65.28% examples, 752339 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:15,997 : INFO : EPOCH 22 - PROGRESS: at 74.92% examples, 755922 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:17,009 : INFO : EPOCH 22 - PROGRESS: at 84.80% examples, 760853 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:18,017 : INFO : EPOCH 22 - PROGRESS: at 94.91% examples, 766823 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:18,434 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:38:18,440 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:38:18,444 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:38:18,446 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:38:18,460 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:38:18,462 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:38:18,476 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:38:18,478 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:38:18,479 : INFO : EPOCH - 22 : training on 9227204 raw words (8222342 effective words) took 10.6s, 773016 effective words/s\n",
      "2020-02-26 18:38:19,492 : INFO : EPOCH 23 - PROGRESS: at 9.23% examples, 754222 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:20,507 : INFO : EPOCH 23 - PROGRESS: at 19.08% examples, 776317 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:21,519 : INFO : EPOCH 23 - PROGRESS: at 27.96% examples, 758217 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:22,524 : INFO : EPOCH 23 - PROGRESS: at 37.48% examples, 763539 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:23,550 : INFO : EPOCH 23 - PROGRESS: at 46.89% examples, 761816 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:24,565 : INFO : EPOCH 23 - PROGRESS: at 56.51% examples, 765123 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:25,578 : INFO : EPOCH 23 - PROGRESS: at 66.15% examples, 767619 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:26,599 : INFO : EPOCH 23 - PROGRESS: at 75.78% examples, 768710 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:27,620 : INFO : EPOCH 23 - PROGRESS: at 85.23% examples, 767669 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:28,634 : INFO : EPOCH 23 - PROGRESS: at 94.36% examples, 764582 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:29,179 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:38:29,186 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:38:29,188 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:38:29,204 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:38:29,209 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:38:29,211 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:38:29,224 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:38:29,232 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:38:29,233 : INFO : EPOCH - 23 : training on 9227204 raw words (8221968 effective words) took 10.7s, 765208 effective words/s\n",
      "2020-02-26 18:38:30,246 : INFO : EPOCH 24 - PROGRESS: at 8.15% examples, 664434 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:31,257 : INFO : EPOCH 24 - PROGRESS: at 17.78% examples, 724239 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:32,260 : INFO : EPOCH 24 - PROGRESS: at 27.10% examples, 737562 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:33,262 : INFO : EPOCH 24 - PROGRESS: at 36.72% examples, 750919 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:34,278 : INFO : EPOCH 24 - PROGRESS: at 46.35% examples, 756777 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:35,311 : INFO : EPOCH 24 - PROGRESS: at 55.42% examples, 751310 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:36,316 : INFO : EPOCH 24 - PROGRESS: at 63.54% examples, 739122 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:37,325 : INFO : EPOCH 24 - PROGRESS: at 72.53% examples, 738209 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:38,360 : INFO : EPOCH 24 - PROGRESS: at 82.21% examples, 741421 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:39,376 : INFO : EPOCH 24 - PROGRESS: at 91.53% examples, 742573 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:40,176 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:38:40,185 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:38:40,199 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:38:40,204 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:38:40,228 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:38:40,234 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:38:40,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:38:40,242 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:38:40,242 : INFO : EPOCH - 24 : training on 9227204 raw words (8222038 effective words) took 11.0s, 747339 effective words/s\n",
      "2020-02-26 18:38:41,286 : INFO : EPOCH 25 - PROGRESS: at 8.90% examples, 705940 words/s, in_qsize 13, out_qsize 5\n",
      "2020-02-26 18:38:42,296 : INFO : EPOCH 25 - PROGRESS: at 18.87% examples, 757841 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:43,337 : INFO : EPOCH 25 - PROGRESS: at 27.75% examples, 739068 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:44,337 : INFO : EPOCH 25 - PROGRESS: at 36.18% examples, 728176 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:45,359 : INFO : EPOCH 25 - PROGRESS: at 45.26% examples, 728945 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:46,375 : INFO : EPOCH 25 - PROGRESS: at 54.35% examples, 730323 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:47,400 : INFO : EPOCH 25 - PROGRESS: at 63.65% examples, 732815 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:38:48,401 : INFO : EPOCH 25 - PROGRESS: at 72.43% examples, 731323 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:49,418 : INFO : EPOCH 25 - PROGRESS: at 81.23% examples, 728809 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:50,429 : INFO : EPOCH 25 - PROGRESS: at 90.32% examples, 729902 words/s, in_qsize 16, out_qsize 1\n",
      "2020-02-26 18:38:51,333 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:38:51,344 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:38:51,348 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:38:51,351 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:38:51,354 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:38:51,372 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:38:51,376 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:38:51,378 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:38:51,379 : INFO : EPOCH - 25 : training on 9227204 raw words (8222791 effective words) took 11.1s, 738889 effective words/s\n",
      "2020-02-26 18:38:52,399 : INFO : EPOCH 26 - PROGRESS: at 9.34% examples, 760351 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:53,407 : INFO : EPOCH 26 - PROGRESS: at 18.97% examples, 773089 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:38:54,421 : INFO : EPOCH 26 - PROGRESS: at 28.83% examples, 782042 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:55,423 : INFO : EPOCH 26 - PROGRESS: at 38.67% examples, 788764 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:56,426 : INFO : EPOCH 26 - PROGRESS: at 48.19% examples, 787303 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:57,440 : INFO : EPOCH 26 - PROGRESS: at 57.71% examples, 785050 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:38:58,460 : INFO : EPOCH 26 - PROGRESS: at 67.45% examples, 785130 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:38:59,488 : INFO : EPOCH 26 - PROGRESS: at 77.31% examples, 785553 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:00,517 : INFO : EPOCH 26 - PROGRESS: at 87.18% examples, 785817 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:01,521 : INFO : EPOCH 26 - PROGRESS: at 96.85% examples, 786160 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:01,743 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:01,748 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:01,753 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:01,758 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:01,774 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:01,779 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:01,785 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:01,786 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:01,787 : INFO : EPOCH - 26 : training on 9227204 raw words (8222380 effective words) took 10.4s, 790966 effective words/s\n",
      "2020-02-26 18:39:02,802 : INFO : EPOCH 27 - PROGRESS: at 8.69% examples, 710335 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:03,817 : INFO : EPOCH 27 - PROGRESS: at 17.68% examples, 719339 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:04,842 : INFO : EPOCH 27 - PROGRESS: at 26.88% examples, 726013 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:05,850 : INFO : EPOCH 27 - PROGRESS: at 36.29% examples, 736683 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:06,860 : INFO : EPOCH 27 - PROGRESS: at 44.94% examples, 730424 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:07,870 : INFO : EPOCH 27 - PROGRESS: at 54.46% examples, 738118 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:08,887 : INFO : EPOCH 27 - PROGRESS: at 64.30% examples, 746547 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:09,900 : INFO : EPOCH 27 - PROGRESS: at 73.51% examples, 746743 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:10,900 : INFO : EPOCH 27 - PROGRESS: at 83.29% examples, 752783 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:11,924 : INFO : EPOCH 27 - PROGRESS: at 92.72% examples, 753088 words/s, in_qsize 15, out_qsize 3\n",
      "2020-02-26 18:39:12,547 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:12,570 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:12,572 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:12,574 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:12,589 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:12,596 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:12,598 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:12,603 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:12,603 : INFO : EPOCH - 27 : training on 9227204 raw words (8222679 effective words) took 10.8s, 761051 effective words/s\n",
      "2020-02-26 18:39:13,644 : INFO : EPOCH 28 - PROGRESS: at 8.90% examples, 713380 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:14,666 : INFO : EPOCH 28 - PROGRESS: at 18.87% examples, 757067 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:15,684 : INFO : EPOCH 28 - PROGRESS: at 28.50% examples, 764462 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:16,685 : INFO : EPOCH 28 - PROGRESS: at 37.70% examples, 762445 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:17,728 : INFO : EPOCH 28 - PROGRESS: at 47.32% examples, 761889 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:18,730 : INFO : EPOCH 28 - PROGRESS: at 56.95% examples, 766785 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:19,733 : INFO : EPOCH 28 - PROGRESS: at 66.15% examples, 765060 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:20,739 : INFO : EPOCH 28 - PROGRESS: at 76.44% examples, 774514 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:21,771 : INFO : EPOCH 28 - PROGRESS: at 85.99% examples, 772820 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:22,784 : INFO : EPOCH 28 - PROGRESS: at 95.55% examples, 772879 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:23,178 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:23,184 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:23,187 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:23,194 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:23,196 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:23,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:23,220 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:23,221 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:23,221 : INFO : EPOCH - 28 : training on 9227204 raw words (8221935 effective words) took 10.6s, 775536 effective words/s\n",
      "2020-02-26 18:39:24,237 : INFO : EPOCH 29 - PROGRESS: at 8.69% examples, 707643 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:25,274 : INFO : EPOCH 29 - PROGRESS: at 18.76% examples, 753766 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:26,280 : INFO : EPOCH 29 - PROGRESS: at 28.61% examples, 770978 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:27,284 : INFO : EPOCH 29 - PROGRESS: at 37.59% examples, 762365 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:28,308 : INFO : EPOCH 29 - PROGRESS: at 46.24% examples, 748926 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:39:29,314 : INFO : EPOCH 29 - PROGRESS: at 55.21% examples, 746719 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:30,315 : INFO : EPOCH 29 - PROGRESS: at 64.40% examples, 748114 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:31,323 : INFO : EPOCH 29 - PROGRESS: at 73.73% examples, 749531 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:32,343 : INFO : EPOCH 29 - PROGRESS: at 83.40% examples, 752655 words/s, in_qsize 15, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:39:33,357 : INFO : EPOCH 29 - PROGRESS: at 92.94% examples, 754586 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:33,996 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:34,003 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:34,004 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:34,016 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:34,017 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:34,028 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:34,042 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:34,043 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:34,044 : INFO : EPOCH - 29 : training on 9227204 raw words (8222084 effective words) took 10.8s, 760314 effective words/s\n",
      "2020-02-26 18:39:35,057 : INFO : EPOCH 30 - PROGRESS: at 8.58% examples, 702227 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:36,058 : INFO : EPOCH 30 - PROGRESS: at 17.78% examples, 729135 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:37,072 : INFO : EPOCH 30 - PROGRESS: at 27.64% examples, 752896 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:38,076 : INFO : EPOCH 30 - PROGRESS: at 37.81% examples, 773005 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:39:39,097 : INFO : EPOCH 30 - PROGRESS: at 47.97% examples, 782646 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:40,104 : INFO : EPOCH 30 - PROGRESS: at 57.71% examples, 785059 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:41,126 : INFO : EPOCH 30 - PROGRESS: at 66.80% examples, 777415 words/s, in_qsize 15, out_qsize 2\n",
      "2020-02-26 18:39:42,144 : INFO : EPOCH 30 - PROGRESS: at 74.92% examples, 762178 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:43,145 : INFO : EPOCH 30 - PROGRESS: at 83.94% examples, 759538 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:39:44,167 : INFO : EPOCH 30 - PROGRESS: at 93.26% examples, 758495 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:44,799 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:44,808 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:44,815 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:44,832 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:44,834 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:44,840 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:44,847 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:44,850 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:44,851 : INFO : EPOCH - 30 : training on 9227204 raw words (8223400 effective words) took 10.8s, 761693 effective words/s\n",
      "2020-02-26 18:39:45,862 : INFO : EPOCH 31 - PROGRESS: at 8.37% examples, 684142 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:46,874 : INFO : EPOCH 31 - PROGRESS: at 17.57% examples, 716331 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:47,878 : INFO : EPOCH 31 - PROGRESS: at 26.23% examples, 714240 words/s, in_qsize 12, out_qsize 3\n",
      "2020-02-26 18:39:48,907 : INFO : EPOCH 31 - PROGRESS: at 34.46% examples, 699867 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:49,926 : INFO : EPOCH 31 - PROGRESS: at 43.64% examples, 708537 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:50,946 : INFO : EPOCH 31 - PROGRESS: at 53.59% examples, 724500 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:51,954 : INFO : EPOCH 31 - PROGRESS: at 62.36% examples, 723322 words/s, in_qsize 16, out_qsize 0\n",
      "2020-02-26 18:39:52,973 : INFO : EPOCH 31 - PROGRESS: at 70.59% examples, 715925 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:53,979 : INFO : EPOCH 31 - PROGRESS: at 78.40% examples, 707261 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:55,003 : INFO : EPOCH 31 - PROGRESS: at 85.77% examples, 695575 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:39:56,004 : INFO : EPOCH 31 - PROGRESS: at 93.81% examples, 692227 words/s, in_qsize 15, out_qsize 1\n",
      "2020-02-26 18:39:56,553 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:39:56,564 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:39:56,577 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:39:56,583 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:39:56,585 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:39:56,588 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:39:56,597 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:39:56,598 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:39:56,599 : INFO : EPOCH - 31 : training on 9227204 raw words (8222852 effective words) took 11.7s, 700459 effective words/s\n",
      "2020-02-26 18:39:57,639 : INFO : EPOCH 32 - PROGRESS: at 9.23% examples, 746636 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:39:58,643 : INFO : EPOCH 32 - PROGRESS: at 17.89% examples, 728037 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:39:59,650 : INFO : EPOCH 32 - PROGRESS: at 26.88% examples, 730288 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:40:00,681 : INFO : EPOCH 32 - PROGRESS: at 35.10% examples, 711569 words/s, in_qsize 15, out_qsize 2\n",
      "2020-02-26 18:40:01,684 : INFO : EPOCH 32 - PROGRESS: at 42.89% examples, 697270 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:40:02,695 : INFO : EPOCH 32 - PROGRESS: at 51.10% examples, 692653 words/s, in_qsize 13, out_qsize 2\n",
      "2020-02-26 18:40:03,719 : INFO : EPOCH 32 - PROGRESS: at 59.98% examples, 695615 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:40:04,734 : INFO : EPOCH 32 - PROGRESS: at 69.29% examples, 703057 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:40:05,738 : INFO : EPOCH 32 - PROGRESS: at 78.40% examples, 707685 words/s, in_qsize 14, out_qsize 1\n",
      "2020-02-26 18:40:06,739 : INFO : EPOCH 32 - PROGRESS: at 88.26% examples, 717786 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:40:07,751 : INFO : EPOCH 32 - PROGRESS: at 97.93% examples, 723746 words/s, in_qsize 15, out_qsize 0\n",
      "2020-02-26 18:40:07,889 : INFO : worker thread finished; awaiting finish of 7 more threads\n",
      "2020-02-26 18:40:07,895 : INFO : worker thread finished; awaiting finish of 6 more threads\n",
      "2020-02-26 18:40:07,897 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2020-02-26 18:40:07,899 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2020-02-26 18:40:07,913 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2020-02-26 18:40:07,926 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-02-26 18:40:07,928 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-02-26 18:40:07,930 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-02-26 18:40:07,931 : INFO : EPOCH - 32 : training on 9227204 raw words (8222029 effective words) took 11.3s, 727281 effective words/s\n",
      "2020-02-26 18:40:07,931 : INFO : training on a 295270528 raw words (263125845 effective words) took 350.0s, 751779 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 45s, sys: 6.32 s, total: 25min 51s\n",
      "Wall time: 5min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(263125845, 295270528)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_model.train(documents, total_examples=len(documents), epochs=W2V_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "27cc2651c74227115d8bfd8c40e5618048e05edd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "2020-02-26 18:42:47,385 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('luv', 0.5717260837554932),\n",
       " ('loves', 0.558630645275116),\n",
       " ('loved', 0.5431678295135498),\n",
       " ('adore', 0.5245904326438904),\n",
       " ('amazing', 0.5016398429870605),\n",
       " ('looove', 0.4788050055503845),\n",
       " ('awesome', 0.4703221917152405),\n",
       " ('loooove', 0.4682392477989197),\n",
       " ('loveee', 0.45412003993988037),\n",
       " ('loove', 0.44265955686569214)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e13563644468037258598637b49373ca96b9b879"
   },
   "source": [
    "### Tokenize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "6852bc709a7cd20173cbeeb218505078f8f37c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words 290419\n",
      "CPU times: user 18.3 s, sys: 92 ms, total: 18.4 s\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df_train.text)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Total words\", vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "45de439df3015030c71f84c2d170346936a1d68f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.6 s, sys: 1.04 s, total: 28.6 s\n",
      "Wall time: 28.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "x_train = pad_sequences(tokenizer.texts_to_sequences(df_train.text), maxlen=SEQUENCE_LENGTH)\n",
    "x_test = pad_sequences(tokenizer.texts_to_sequences(df_test.text), maxlen=SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "03b35903fc6260e190d6928d240ef7432de117fc"
   },
   "source": [
    "### Label Encoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "33676e0efa39e97d89bd650b8b4eae933a22fbf0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVE', 'NEGATIVE', 'NEUTRAL']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train.target.unique().tolist()\n",
    "labels.append(NEUTRAL)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "04239a9bef76e7922fd86098a5601dfde8ee4665"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train (1280000, 1)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(df_train.target.tolist())\n",
    "\n",
    "y_train = encoder.transform(df_train.target.tolist())\n",
    "y_test = encoder.transform(df_test.target.tolist())\n",
    "\n",
    "y_train = y_train.reshape(-1,1)\n",
    "y_test = y_test.reshape(-1,1)\n",
    "\n",
    "print(\"y_train\",y_train.shape)\n",
    "print(\"y_test\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "04299c886911ca135583ab64878f213939a2990c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train (1280000, 300)\n",
      "y_train (1280000, 1)\n",
      "\n",
      "x_test (320000, 300)\n",
      "y_test (320000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train\", x_train.shape)\n",
    "print(\"y_train\", y_train.shape)\n",
    "print()\n",
    "print(\"x_test\", x_test.shape)\n",
    "print(\"y_test\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "232533fb27b7be99d9b8c2f8fb22c9c6bf121a6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "233c0ea94055a03e2e7df3e2a13d036ec963484f"
   },
   "source": [
    "### Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "9ab488374b59e3f30f8b1ea92767d853c4846bac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290419, 300)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, W2V_SIZE))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "  if word in w2v_model.wv:\n",
    "    embedding_matrix[i] = w2v_model.wv[word]\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "833279d91e4286065968237fb5f2a0c2dd4d246c"
   },
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(vocab_size, W2V_SIZE, weights=[embedding_matrix], input_length=SEQUENCE_LENGTH, trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b299ef78f94c2085942c993a2d58753a7476305a"
   },
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "e775ef4f1b74e6412457181383c39f2df554ef3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:47:18,015 : WARNING : Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 300, 300)          87125700  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 300, 300)          0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 87,286,201\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 87,125,700\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "28d22eafd0c7d798dcf3d742bc92fb8577939e6c"
   },
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "1331e08d590bb2aa2033706c8faca217afc0f1c3"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7733127cb8b380e0c807268903bf4d03ef92542"
   },
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "a688df590386f5748da6fe00b01904fe6c71619e"
   },
   "outputs": [],
   "source": [
    "callbacks = [ ReduceLROnPlateau(monitor='val_loss', patience=5, cooldown=0),\n",
    "              EarlyStopping(monitor='val_acc', min_delta=1e-4, patience=5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8d0873633dd49179c8cae17377641b97d323ef3b"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "2b659d390c6577dc5cdb6b6297934279b4e801d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1152000 samples, validate on 128000 samples\n",
      "Epoch 1/8\n",
      "1150976/1152000 [============================>.] - ETA: 0s - loss: 0.5048 - accuracy: 0.7493WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 18:55:25,661 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152000/1152000 [==============================] - 462s 401us/sample - loss: 0.5048 - accuracy: 0.7494 - val_loss: 0.4650 - val_accuracy: 0.7798\n",
      "Epoch 2/8\n",
      "1150976/1152000 [============================>.] - ETA: 0s - loss: 0.4795 - accuracy: 0.7673WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 19:02:56,364 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1152000/1152000 [==============================] - 451s 391us/sample - loss: 0.4795 - accuracy: 0.7674 - val_loss: 0.4575 - val_accuracy: 0.7842\n",
      "Epoch 3/8\n",
      " 796672/1152000 [===================>..........] - ETA: 2:14 - loss: 0.4752 - accuracy: 0.7702WARNING:tensorflow:Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 19:07:56,948 : WARNING : Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-02-26 19:07:56,950 : WARNING : Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,lr\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    605\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2412\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2413\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2414\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1658\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1659\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1660\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1662\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1739\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1740\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1741\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1742\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1743\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_split=0.1,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "267258196d96796ac69a7b8c466314bcf5d6ee42"
   },
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "98ecd8f1b8b74594c3ea775dd68a094e92458022"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "score = model.evaluate(x_test, y_test, batch_size=BATCH_SIZE)\n",
    "print()\n",
    "print(\"ACCURACY:\",score[1])\n",
    "print(\"LOSS:\",score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "40c72cd1e9d6c4fd799cbba7c813765ac4039dfc"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    " \n",
    "epochs = range(len(acc))\n",
    " \n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    " \n",
    "plt.figure()\n",
    " \n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bdfc0f6a6af5bebc0271d83dd7432c91001409b"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0b0fa3d4b1bb14b3f5e3d169a369f3ebef29ae1"
   },
   "outputs": [],
   "source": [
    "def decode_sentiment(score, include_neutral=True):\n",
    "    if include_neutral:        \n",
    "        label = NEUTRAL\n",
    "        if score <= SENTIMENT_THRESHOLDS[0]:\n",
    "            label = NEGATIVE\n",
    "        elif score >= SENTIMENT_THRESHOLDS[1]:\n",
    "            label = POSITIVE\n",
    "\n",
    "        return label\n",
    "    else:\n",
    "        return NEGATIVE if score < 0.5 else POSITIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed4086d651f2f8cbed11d3c909a8873607d29a06"
   },
   "outputs": [],
   "source": [
    "def predict(text, include_neutral=True):\n",
    "    start_at = time.time()\n",
    "    # Tokenize text\n",
    "    x_test = pad_sequences(tokenizer.texts_to_sequences([text]), maxlen=SEQUENCE_LENGTH)\n",
    "    # Predict\n",
    "    score = model.predict([x_test])[0]\n",
    "    # Decode sentiment\n",
    "    label = decode_sentiment(score, include_neutral=include_neutral)\n",
    "\n",
    "    return {\"label\": label, \"score\": float(score),\n",
    "       \"elapsed_time\": time.time()-start_at}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca38b1e6c9b5acfed7467de2cf02a78333108872"
   },
   "outputs": [],
   "source": [
    "predict(\"I love the music\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e5fe647533be0148850de349fea6ef6f71303d1"
   },
   "outputs": [],
   "source": [
    "predict(\"I hate the rain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "37064dffcc8920d34ccd54fac7c8b50e583a8269"
   },
   "outputs": [],
   "source": [
    "predict(\"i don't know what i'm doing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3ee72e47f84b6dbc32e02a783de5ec1661f157e1"
   },
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0e920173eb05f04aecdd735bc5dff0f5be5f8d15"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "y_pred_1d = []\n",
    "y_test_1d = list(df_test.target)\n",
    "scores = model.predict(x_test, verbose=1, batch_size=8000)\n",
    "y_pred_1d = [decode_sentiment(score, include_neutral=False) for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b3575191bb425ab871f3f41e83812ee84bb7e595"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title, fontsize=30)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90, fontsize=22)\n",
    "    plt.yticks(tick_marks, classes, fontsize=22)\n",
    "\n",
    "    fmt = '.2f'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label', fontsize=25)\n",
    "    plt.xlabel('Predicted label', fontsize=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a57dc6f6211c144491a70f533225edfa95a2dc66"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test_1d, y_pred_1d)\n",
    "plt.figure(figsize=(12,12))\n",
    "plot_confusion_matrix(cnf_matrix, classes=df_train.target.unique(), title=\"Confusion matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e23b957348dcc084249d3cc7538b972da471c2cd"
   },
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a7fe05b7caa1c984ff1deb0be2f7c6bc043df9f5"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test_1d, y_pred_1d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4eb300f0c6693a618587c7dcf32f77f5416cbfb9"
   },
   "source": [
    "### Accuracy Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5cf76e6e09f8a60ed25947932b94c772eda44d23"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test_1d, y_pred_1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4f014c32f3833db282e1a075c526604f34e3158c"
   },
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3b2b3ad5b592977b404acfa1c9ad303a62837255"
   },
   "outputs": [],
   "source": [
    "model.save(KERAS_MODEL)\n",
    "w2v_model.save(WORD2VEC_MODEL)\n",
    "pickle.dump(tokenizer, open(TOKENIZER_MODEL, \"wb\"), protocol=0)\n",
    "pickle.dump(encoder, open(ENCODER_MODEL, \"wb\"), protocol=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
